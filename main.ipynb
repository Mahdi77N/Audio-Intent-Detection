{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(csv_path=\"./dsl_data/development.csv\"):\n",
    "    \"\"\"Read the data, based on the \"development.csv\" file. it will read the audio files, and return two pandas dataFrame, x and y.\n",
    "       it will not normalize the data. also will not change the data to categorical.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str, optional): path to the \"development.csv\" file. Defaults to \"./dsl_data/development.csv\".\n",
    "\n",
    "    Returns:\n",
    "        pandas dataFrame: the x has all the features, excluding \"path\", \"action\", \"object\" and \"Id\".\n",
    "        the y has \"action\", \"object\", and \"intention\" which is a new feature by adding the other two columns.\n",
    "        int: sample rate\n",
    "    \"\"\"\n",
    "\n",
    "    development_pd = pd.read_csv(csv_path)  # .drop([\"Id\"], axis=1)\n",
    "    development_pd[\"Signal\"] = \"\"\n",
    "\n",
    "    for index, row in development_pd.iterrows():\n",
    "        wave, srr = librosa.load(row[\"path\"], mono=True, sr=None)\n",
    "        development_pd.at[index, \"Signal\"] = wave\n",
    "\n",
    "    x = development_pd.drop([\"Id\", \"action\", \"object\", \"path\"], axis=1)\n",
    "    y = development_pd[[\"action\", \"object\"]]\n",
    "    y[\"intention\"] = development_pd[\"action\"] + development_pd[\"object\"]\n",
    "\n",
    "    return x, y, srr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audios(x, top_db=30, hop_length=50):\n",
    "    \"\"\"Trim the audios in the X.\n",
    "\n",
    "    Args:\n",
    "        x (pandas dataFrame): DataFrame consist of features, incuding the audios\n",
    "        top_db (int, optional): audio's db less than this number will consider as silent. Defaults to 30.\n",
    "        hop_length (int, optional): sensitivity of triming. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "        pandas dataFrame: features DataFrame, with trimed audio in the \"Signal\" column.\n",
    "    \"\"\"\n",
    "    for index, row in x.iterrows():\n",
    "        wave, i = librosa.effects.trim(\n",
    "            row[\"Signal\"], top_db=top_db, hop_length=hop_length\n",
    "        )\n",
    "        x.at[index, \"Signal\"] = wave\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mfcc(x, srr, max_pad_len=215):\n",
    "    \"\"\"convert the audio signal to MFCC\n",
    "\n",
    "    Args:\n",
    "        x (pandas dataFrame): our data set\n",
    "        srr (int): sample rate\n",
    "        max_pad_len (int, optional): maximum width of MFCC. all MFCCs will be in width of max_pad_len. Defaults to 215.\n",
    "\n",
    "    Returns:\n",
    "        pandas dataFrame: our data set\n",
    "    \"\"\"\n",
    "    for index, row in x.iterrows():\n",
    "        mfcc = librosa.feature.mfcc(y=row[\"Signal\"], sr=srr)\n",
    "        pad_width = max_pad_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode=\"constant\")\n",
    "\n",
    "        x.at[index, \"Signal\"] = mfcc\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ehtes\\AppData\\Local\\Temp\\ipykernel_1436\\2289199453.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[\"intention\"] = development_pd[\"action\"] + development_pd[\"object\"]\n"
     ]
    }
   ],
   "source": [
    "X, Y, srr = read_data()\n",
    "X_trimed = trim_audios(X.copy(), top_db=10, hop_length=10)\n",
    "X_mfcc = convert_to_mfcc(X_trimed.copy(), srr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c663c866a1fb96859a8987df8dcaf456bb4d601a775f22c0ae8b5e612b0ffc21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
