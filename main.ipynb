{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "import keras\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(csv_path=\"./dsl_data/development.csv\", data=\"train\"):\n",
    "    \"\"\"Read the data, based on the the CSV file given. it can be the train or test data.\n",
    "    in case of test data, only X and sample rate will return. in case of train data, X,Y, and sample rate will return.\n",
    "    X and Y are in Pandas DataFrame format.\n",
    "    it will not normalize the data. also will not change the data to categorical.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str, optional): path to the CSV file. Defaults to \"./dsl_data/development.csv\".\n",
    "        data (str, optional): the the data is train data, set to train. else, it will be test data. Defaults to \"train\".\n",
    "\n",
    "    Returns:\n",
    "        pandas dataFrame:  In case of Train data, the X has all the features, excluding \"path\", \"action\", \"object\" and \"Id\".\n",
    "        the y has \"action\", \"object\", and \"intention\" which is a new feature by adding the other two columns.\n",
    "        in case of Test data, the X will be test data without \"path\" column.\n",
    "        int: sample rate\n",
    "    \"\"\"\n",
    "\n",
    "    development_pd = pd.read_csv(csv_path)\n",
    "    development_pd[\"Signal\"] = \"\"\n",
    "\n",
    "    for index, row in development_pd.iterrows():\n",
    "        wave, srr = librosa.load(row[\"path\"], mono=True, sr=None)\n",
    "        development_pd.at[index, \"Signal\"] = wave\n",
    "\n",
    "    if data == \"train\":\n",
    "        x = development_pd.drop([\"Id\", \"action\", \"object\", \"path\"], axis=1)\n",
    "        y = development_pd[[\"action\", \"object\"]]\n",
    "        y[\"intention\"] = development_pd[\"action\"] + development_pd[\"object\"]\n",
    "        return x, y, srr\n",
    "\n",
    "    else:\n",
    "        x = development_pd.drop([\"path\"], axis=1)\n",
    "        return x, srr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audios(x, top_db=30, hop_length=50):\n",
    "    \"\"\"Trim the audios in the X.\n",
    "\n",
    "    Args:\n",
    "        x (pandas dataFrame): DataFrame consist of features, incuding the audios\n",
    "        top_db (int, optional): audio's db less than this number will consider as silent. Defaults to 30.\n",
    "        hop_length (int, optional): sensitivity of triming. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "        pandas dataFrame: features DataFrame, with trimed audio in the \"Signal\" column.\n",
    "    \"\"\"\n",
    "    for index, row in x.iterrows():\n",
    "        wave, i = librosa.effects.trim(\n",
    "            row[\"Signal\"], top_db=top_db, hop_length=hop_length\n",
    "        )\n",
    "        x.at[index, \"Signal\"] = wave\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef convert_to_mfcc(x, srr, max_audio_len=3):\n",
    "    \"\"\"convert the audio signal to MFCC\n",
    "\n",
    "    Args:\n",
    "        x (pandas dataFrame): our data set\n",
    "        srr (int): sample rate\n",
    "        max_audio_len (int, optional): maximum audio length in data. used for set the maximum width for MFCCs. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        pandas dataFrame: our data set\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in x.iterrows():\n",
    "        mfcc = librosa.feature.mfcc(row[\"Signal\"], sr=srr)\n",
    "        max_pad_len = (max_audio_len * srr) / 512\n",
    "        pad_width = ceil(max_pad_len - mfcc.shape[1])\n",
    "\n",
    "        if mfcc.shape[1] <= max_pad_len:\n",
    "            mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode=\"constant\")\n",
    "        else:\n",
    "            mfcc = mfcc[:, 0 : ceil(max_pad_len)]\n",
    "        x.at[index, \"Signal\"] = np.array(mfcc)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numpy(x, x_columns, y=None, y_columns=None, data=\"train\"):\n",
    "    \"\"\"Convert our data from pandas dataFrame to numpy array. Also, will drop all columns execpt the x_columns and y_columns\n",
    "\n",
    "    Args:\n",
    "        x (pandas dataFrame): our train set's features\n",
    "        y (pandas dataFrame, optinal): train set's classes. Ignore if your data is test data.\n",
    "        x_columns (array): features in train set that we want to train the model with them.\n",
    "        y_columns (array, optional): one of three classes, from \"object\", \"action\", and \"intention\". Ignore if your data is test data.\n",
    "        data (str, optional): the the data is train data, set to train. else, it will be test data. Defaults to \"train\".\n",
    "\n",
    "    Returns:\n",
    "        numpay arrays: will return x and y in numpy arrays and only with specified columns for train data, and only X for test data.\n",
    "    \"\"\"\n",
    "    x_temp = x[x_columns]\n",
    "    x_temp_2 = np.array([x_temp.iloc[i][\"Signal\"] for i in range(len(x_temp))])\n",
    "    print(type(y))\n",
    "    if data != \"train\":\n",
    "        return x_temp_2\n",
    "\n",
    "    else:\n",
    "        y_temp = y[y_columns]\n",
    "        y_temp = y_temp.to_numpy()\n",
    "\n",
    "        return x_temp_2, y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_oneHot(y):\n",
    "    \"\"\"encode the classes from strings to oneHot\n",
    "\n",
    "    Args:\n",
    "        y (numpy array): train set's classes\n",
    "\n",
    "    Returns:\n",
    "        numpy array: train set's classes in oneHot format.\n",
    "        Label encoder Object: in order to be able to inverse oneHot to strings when we have the results.\n",
    "\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    temp = le.fit_transform(y)\n",
    "    y_oneHot = to_categorical(temp, num_classes=max(temp) + 1)\n",
    "\n",
    "    return y_oneHot, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef get_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            32,\n",
    "            kernel_size=(2, 2),\n",
    "            activation=\"relu\",\n",
    "            input_shape=input_shape,\n",
    "            strides=(1, 2),\n",
    "            padding=\"same\",\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            48, kernel_size=(2, 2), activation=\"relu\", strides=(1, 2), padding=\"same\"\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            120, kernel_size=(2, 2), activation=\"relu\", strides=(1, 2), padding=\"same\"\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.15))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(x, y, max_length=3):\n",
    "    \"\"\"will remove the outliers from the dataset\n",
    "\n",
    "    Args:\n",
    "        x (Pandas DataFrame): our dataset\n",
    "        y (Pandas DataFrame): our classes\n",
    "        max_length (int, optional): maximum audio lengths. the function will remove audios with length greated than this. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame: our dataset and classes after removing outliers\n",
    "    \"\"\"\n",
    "    t = []\n",
    "    for index, row in X_trimed.iterrows():\n",
    "        t.append(librosa.get_duration(row[\"Signal\"], sr=srr))\n",
    "\n",
    "    ouliers_index = np.where(np.array(t) > max_length)\n",
    "\n",
    "    x_removed_ouliers = x.copy().drop(ouliers_index[0], axis=0)\n",
    "    y_removed_ouliers = y.copy().drop(ouliers_index[0], axis=0)\n",
    "\n",
    "    return x_removed_ouliers, y_removed_ouliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_output_csv(\n",
    "    saved_model_path,\n",
    "    output_csv_path,\n",
    "    evaluate_csv_path,\n",
    "    le,\n",
    "    max_audio_length,\n",
    "    top_db=10,\n",
    "    hop_length=10,\n",
    "):\n",
    "    \"\"\"generate output csv file for the test dataset\n",
    "\n",
    "    Args:\n",
    "        saved_model_path (str): path to the saved model, like H5 or HDF5 file.\n",
    "        output_csv_path (csv): path for the new output CSV file.\n",
    "        evaluate_csv_path (str): path to the CSV file of the test data.\n",
    "        le (Label encoder Object): Label encoder Object for reverse the encoding from str to oneHot\n",
    "        max_audio_length (int): maximum audio length between our dataset in TRAIN set.\n",
    "        top_db (int, optional): audio's db less than this number will consider as silent. Defaults to 30.\n",
    "        hop_length (int, optional): sensitivity of triming. Defaults to 50.\n",
    "    \"\"\"\n",
    "    model = load_model(saved_model_path)\n",
    "    x_test, srr_test = read_data(csv_path=evaluate_csv_path, data=\"Not_train\")\n",
    "    X_test_trimed = trim_audios(x_test, top_db=top_db, hop_length=hop_length)\n",
    "    X_mfcc_test = convert_to_mfcc(\n",
    "        X_test_trimed.copy(), srr_test, max_audio_len=max_audio_length\n",
    "    )\n",
    "    X_n_test = convert_to_numpy(X_mfcc_test, [\"Signal\"], data=\"not train\")\n",
    "    predicted_y = model.predict(X_n_test)\n",
    "    predicted_y = np.argmax(predicted_y, axis=1)\n",
    "    predicted_y_string = le.inverse_transform(predicted_y)\n",
    "    df = pd.DataFrame(predicted_y_string)\n",
    "    df[\"Id\"] = df.index\n",
    "    df = df.iloc[:, [1, 0]]\n",
    "    df.rename(columns={0: \"Predicted\"}, inplace=True)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght = 2.5\n",
    "\n",
    "X, Y, srr = read_data()\n",
    "X_trimed = trim_audios(X, top_db=10, hop_length=10)\n",
    "\n",
    "X_no_outliers, y_no_outliers = remove_outliers(X_trimed, Y, max_length=max_lenght)\n",
    "X_mfcc = convert_to_mfcc(X_no_outliers, srr, max_audio_len=max_lenght)\n",
    "\n",
    "X_n, Y_n = convert_to_numpy(\n",
    "    x=X_mfcc,\n",
    "    x_columns=[\"Signal\"],\n",
    "    y=y_no_outliers,\n",
    "    y_columns=[\"intention\"],\n",
    "    data=\"train\",\n",
    ")\n",
    "y_oneHot, le = convert_y_to_oneHot(Y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_1 = X_n.shape[1]\n",
    "dim_2 = X_n.shape[2]\n",
    "channels = 1\n",
    "classes = y_oneHot.shape[1]\n",
    "X_n = X_n.reshape((X_n.shape[0], dim_1, dim_2, channels))\n",
    "input_shape = (dim_1, dim_2, channels)\n",
    "\n",
    "cnn_model = get_cnn_model(input_shape, classes)\n",
    "print(cnn_model.summary())\n",
    "\n",
    "keras_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./Graph\", histogram_freq=1, write_graph=True, write_images=True\n",
    ")\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=\"./audio_classification.hdf5\", verbose=1, save_best_only=True\n",
    ")\n",
    "\n",
    "h = cnn_model.fit(\n",
    "    X_n,\n",
    "    y_oneHot,\n",
    "    batch_size=8,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    validation_split=0.20,\n",
    "    callbacks=[keras_callback, checkpointer],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# USE THIS FOR LOAD and GERATE OUTPUT\n",
    "##########################################################\n",
    "# test_output_csv(\n",
    "#     saved_model_path=\"audio_classification.hdf5\",\n",
    "#     output_csv_path=\"output.csv\",\n",
    "#     evaluate_csv_path=\"./dsl_data/evaluation.csv\",\n",
    "#     max_audio_length=max_lenght,\n",
    "#     le=le,\n",
    "# )\n",
    "############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c663c866a1fb96859a8987df8dcaf456bb4d601a775f22c0ae8b5e612b0ffc21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
